# -*- coding: utf-8 -*-
"""deeplabv3-resnet50-mineral15k.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11qa4vIxbP52KE9JMxG6Vy6ZfO2Cz3nfa
"""

import os

dataset_path = "/kaggle/input/minerals-creative-7k/minerals-creative-7k"
train_images_path = os.path.join(dataset_path, "images/train")
train_masks_path = os.path.join(dataset_path, "annotations/train")

dataset_path_test = "/kaggle/input/minerals-creative-7k/minerals-creative-7k"
test_images_path = os.path.join(dataset_path_test, "images/test")
test_masks_path = os.path.join(dataset_path_test, "annotations/test")

print("Train Images:", len(os.listdir(train_images_path)))
print("Train Masks:", len(os.listdir(train_masks_path)))
print("Test Images:", len(os.listdir(test_images_path)))
print("Test Masks:", len(os.listdir(test_masks_path)))

print("\nПримеры файлов (Train Images):", os.listdir(train_images_path)[:5])
print("Примеры файлов (Train Masks):", os.listdir(train_masks_path)[:5])

import matplotlib.pyplot as plt
import cv2
import numpy as np
from PIL import Image

# Функция для загрузки и отображения изображения и маски
def visualize_sample(image_path, mask_path):
    if not os.path.exists(image_path):
        print(f"Изображение не найдено: {image_path}")
        return
    if not os.path.exists(mask_path):
        print(f"Маска не найдена: {mask_path}")
        return

    image = cv2.imread(image_path, cv2.IMREAD_COLOR)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    mask = Image.open(mask_path).convert("L")
    mask = np.array(mask)


    print(f"Изображение: {image.shape}, Маска: {mask.shape}, dtype: {mask.dtype}")


    fig, ax = plt.subplots(1, 2, figsize=(10, 5))
    ax[0].imshow(image)
    ax[0].set_title("Исходное изображение")
    ax[0].axis("off")

    ax[1].imshow(mask, cmap="gray")
    ax[1].set_title("Маска (размеченные классы)")
    ax[1].axis("off")

    plt.show()


image_files = sorted(os.listdir(train_images_path))
mask_files = sorted(os.listdir(train_masks_path))


sample_image = image_files[0]


sample_mask = os.path.splitext(sample_image)[0] + ".png"


image_path = os.path.join(train_images_path, sample_image)
mask_path = os.path.join(train_masks_path, sample_mask)


visualize_sample(image_path, mask_path)

import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T

# Dataset для сегментации с ресайзом
class PlantSegDataset(Dataset):
    def __init__(self, images_dir, masks_dir, transform=None, img_size=512):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.image_filenames = sorted(os.listdir(images_dir))
        self.transform = transform
        self.img_size = img_size

    def __len__(self):
        return len(self.image_filenames)

    def __getitem__(self, idx):
        image_filename = self.image_filenames[idx]
        mask_filename = os.path.splitext(image_filename)[0] + ".png"
        image_path = os.path.join(self.images_dir, image_filename)
        mask_path = os.path.join(self.masks_dir, mask_filename)

        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        image = cv2.resize(image, (self.img_size, self.img_size))  # Ресайз до 512x512
        image = image.astype(np.float32) / 255.0  # Нормализация [0,1]

        #копируем одно и то же изображение в 3 канала)
        image = np.stack([image, image, image], axis=-1)  # [H, W, 3]

        mask = Image.open(mask_path).convert("L")
        mask = mask.resize((self.img_size, self.img_size), Image.NEAREST)  # Ресайз маски (NEAREST для классов)
        mask = np.array(mask, dtype=np.int64)  # Оставляем как int64 (классы)

        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image, mask = augmented["image"], augmented["mask"]

        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)
        mask = torch.tensor(mask, dtype=torch.long)

        return image, mask

#train
train_dataset = PlantSegDataset(train_images_path, train_masks_path, img_size=512)

sample_img, sample_mask = train_dataset[0]
print(f"Форма изображения: {sample_img.shape}")  # [3, 512, 512]
print(f"Форма маски: {sample_mask.shape}")        # [512, 512]
print(f"Классы в маске: {torch.unique(sample_mask)}")  # Проверяем классы

BATCH_SIZE = 8
NUM_WORKERS = 2

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)

batch_images, batch_masks = next(iter(train_loader))
print(f"Размер batch изображений: {batch_images.shape}")  # [B, 3, 512, 512]
print(f"Размер batch масок: {batch_masks.shape}")        # [B, 512, 512]

mask_files = sorted(os.listdir(train_masks_path))[:1]

for mask_file in mask_files:
    mask_path = os.path.join(train_masks_path, mask_file)
    mask = Image.open(mask_path)
    mask_array = np.array(mask)

    print(f"Маска: {mask_file} → Уникальные классы: {np.unique(mask_array)}")

mask_files = sorted(os.listdir(train_masks_path))

all_classes = set()

for mask_file in mask_files:
    mask_path = os.path.join(train_masks_path, mask_file)
    mask = Image.open(mask_path)
    mask_array = np.array(mask)

    unique_classes = np.unique(mask_array)
    all_classes.update(unique_classes)

print(f"Общее количество уникальных классов: {len(all_classes)}")
print(f"Уникальные классы: {sorted(all_classes)}")

print(len(all_classes))

import torch.nn as nn
import torchvision.models.segmentation as segmentation
from torch.optim import Adam

model = segmentation.deeplabv3_resnet50(pretrained=True)
num_classes = 2  # Включая класс фона
model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1))
model.aux_classifier[4] = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1))

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model.to(device)

# Замораживаем все слои модели, кроме классификаторов
for param in model.parameters():
    param.requires_grad = False

# Размораживаем последний блок и классификаторы (включая aux_classifier)
for param in model.classifier.parameters():
    param.requires_grad = True

# Размораживаем aux_classifier
for param in model.aux_classifier.parameters():
    param.requires_grad = True

# Заменяем последний слой на соответствующее количество классов
num_classes = 2  # Включая класс фона
model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1))
model.aux_classifier[4] = nn.Conv2d(256, num_classes, kernel_size=(1, 1), stride=(1, 1))

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

for name, param in model.named_parameters():
    if param.requires_grad:
        print(f"Обучается: {name}")
    else:
        print(f"Заморожено: {name}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

os.environ['CUDA_LAUNCH_BLOCKING'] = "1"

import torchvision
from torchvision import transforms
from sklearn.metrics import confusion_matrix

for name, param in model.named_parameters():
    if param.requires_grad:
        print(f"{name} разморожен")

train_dataset = PlantSegDataset(train_images_path, train_masks_path, img_size=512)

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, drop_last=True)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

criterion = nn.CrossEntropyLoss()

# Функция для расчета IoU
def calculate_iou(preds, labels, num_classes):
    """
    Функция для расчета IoU для всех классов.
    """
    preds = preds.argmax(dim=1)
    iou_per_class = []
    for i in range(num_classes):
        intersection = ((preds == i) & (labels == i)).sum().item()
        union = ((preds == i) | (labels == i)).sum().item()
        iou = intersection / union if union != 0 else float('nan')
        iou_per_class.append(iou)
    return iou_per_class


epochs = 5
all_losses = []  # Список для хранения потерь
all_ious = []  # Список для хранения IoU на каждой эпохе

for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    iou_list = []  # Список для IoU на одной эпохе

    for batch_idx, (images, masks) in enumerate(train_loader):
        images, masks = images.to(device), masks.to(device)

        optimizer.zero_grad()
        outputs = model(images)

        output = outputs['out']

        loss = criterion(output, masks)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # Вычисляем IoU для текущего батча
        iou_batch = calculate_iou(output, masks, num_classes=2)
        iou_list.append(iou_batch)

        # Выводим потери на каждой 10-й итерации
        if batch_idx % 10 == 0:
            print(f"Эпоха {epoch+1}/{epochs}, Итерация {batch_idx}/{len(train_loader)}, Потери: {running_loss/(batch_idx+1)}")


    avg_loss = running_loss / len(train_loader)
    avg_iou = np.nanmean(iou_list)
    all_losses.append(avg_loss)
    all_ious.append(avg_iou)

    print(f"Эпоха {epoch+1}/{epochs}, Средние потери: {avg_loss:.4f}, Средний IoU: {avg_iou:.4f}")


torch.save(model.state_dict(), "deeplabv3_resnet50-mineralscreative7k.pth")


plt.figure(figsize=(12, 6))


plt.subplot(1, 2, 1)
plt.plot(range(epochs), all_losses, label='Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss')
plt.legend()


plt.subplot(1, 2, 2)
plt.plot(range(epochs), all_ious, label='IoU', color='orange')
plt.xlabel('Epochs')
plt.ylabel('IoU')
plt.title('Mean IoU per Epoch')
plt.legend()

plt.tight_layout()
plt.show()

test_dataset = PlantSegDataset(test_images_path, test_masks_path, img_size=512)
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4, drop_last=True)

model.eval()

predictions = []

with torch.no_grad():
    for images, _ in test_loader:
        images = images.to(device)

        outputs = model(images)
        preds = outputs['out'].argmax(dim=1)

        predictions.extend(preds.cpu().numpy())

print(f"Получены предсказания для {len(predictions)} изображений.")

import random

def apply_mask(image, mask, color=(255, 0, 0), alpha=0.5):
    """Накладывает маску на изображение с прозрачностью."""
    colored_mask = np.zeros_like(image)
    for i in range(3):
        colored_mask[:, :, i] = mask * color[i]

    overlay = cv2.addWeighted(image, 1 - alpha, colored_mask, alpha, 0)
    return overlay

def visualize_predictions(test_loader, predictions, num_samples=10):
    samples = random.sample(range(len(predictions)), num_samples)

    fig, axes = plt.subplots(num_samples, 4, figsize=(16, num_samples * 3))

    for i, idx in enumerate(samples):
        image, mask = test_loader.dataset[idx]
        image = image.cpu().numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)
        mask = mask.cpu().numpy()
        pred_mask = predictions[idx]

        overlay_pred = apply_mask((image * 255).astype(np.uint8), pred_mask, color=(255, 255, 0), alpha=0.5)


        overlay_gt = apply_mask((image * 255).astype(np.uint8), mask, color=(100, 238, 100), alpha=0.5)

        axes[i, 0].imshow(image)
        axes[i, 0].set_title("Original Image")

        axes[i, 1].imshow(overlay_gt)
        axes[i, 1].set_title("Ground Truth Mask Overlay")

        axes[i, 2].imshow(overlay_pred)
        axes[i, 2].set_title("Predicted Mask Overlay")

        axes[i, 3].imshow(pred_mask, cmap='jet', alpha=0.7)
        axes[i, 3].set_title("Predicted Mask")

        for ax in axes[i]:
            ax.axis("off")

    plt.tight_layout()
    plt.show()


visualize_predictions(test_loader, predictions, num_samples=10)

def calculate_iou(preds, labels, num_classes):
    """
    Функция для расчета IoU для всех классов.
    """
    preds = preds.argmax(dim=1)  # Преобразуем [B, C, H, W] -> [B, H, W]

    iou_per_class = []
    for i in range(num_classes):
        intersection = ((preds == i) & (labels == i)).sum().item()
        union = ((preds == i) | (labels == i)).sum().item()
        iou = intersection / union if union != 0 else float('nan')
        iou_per_class.append(iou)

    return np.nanmean(iou_per_class)  # Усредняем IoU по всем классам

def calculate_accuracy(preds, labels):
    correct = (preds == labels).sum().item()
    total = labels.numel()
    return correct / total



test_ious = []
test_accuracies = []

with torch.no_grad():
    for images, masks in test_loader:
        images, masks = images.to(device), masks.to(device)

        outputs = model(images)
        output = outputs['out']
        preds = output.argmax(dim=1)

        iou_batch = calculate_iou(output, masks, num_classes=117)
        test_ious.append(iou_batch)


        acc = calculate_accuracy(preds, masks)
        test_accuracies.append(acc)


mean_iou = np.nanmean(test_ious)
mean_accuracy = np.mean(test_accuracies)

print(f"Средний IoU на тестовой выборке: {mean_iou:.4f}")
print(f"Средняя Accuracy на тестовой выборке: {mean_accuracy:.4f}")

def dice_score(preds, masks, num_classes):

    preds = preds.cpu().numpy()
    masks = masks.cpu().numpy()

    print(f"preds shape: {preds.shape}, masks shape: {masks.shape}")

    dice_per_class = np.zeros(num_classes)

    for i in range(num_classes):
        intersection = np.logical_and(preds == i, masks == i).sum()
        union = (preds == i).sum() + (masks == i).sum()

        if union > 0:
            dice_per_class[i] = (2 * intersection) / union

    mean_dice = np.mean(dice_per_class[dice_per_class > 0])
    return dice_per_class, mean_dice

print(f"preds shape: {preds.shape}, masks shape: {masks.shape}")

preds = model(images)['out'].argmax(dim=1)
batch_dice, mean_dice = dice_score(preds, masks, num_classes)
print(f"Средний Dice Score: {mean_dice:.4f}")

from sklearn.metrics import precision_recall_curve, auc

def calculate_map(preds, masks, num_classes):
    ap_per_class = []

    preds = preds.cpu().numpy()
    masks = masks.cpu().numpy()

    for i in range(1, num_classes):  # Пропускаем фон (0)
        y_true = (masks == i).astype(np.uint8).flatten()
        y_pred = (preds == i).astype(np.uint8).flatten()

        if np.sum(y_true) == 0:
            continue

        precision, recall, _ = precision_recall_curve(y_true, y_pred)
        ap = auc(recall, precision)  # Площадь под PR-кривой
        ap_per_class.append(ap)

    return np.mean(ap_per_class) if ap_per_class else 0.0  # Усредняем по классам

preds = outputs['out'].argmax(dim=1)

mean_ap = calculate_map(preds, masks, num_classes=2)
print(f"Средний mAP: {mean_ap:.4f}")