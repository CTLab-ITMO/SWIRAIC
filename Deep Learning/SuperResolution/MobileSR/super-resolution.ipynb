{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://drive.google.com/file/d/1sb6AS8JH6jxScJP9ZkIB4QTW5WIDHQTW/view?usp=sharing\n!conda install -y gdown\n!gdown --id \"1sb6AS8JH6jxScJP9ZkIB4QTW5WIDHQTW\"\n!unzip -q SWIR.zip\n!rm SWIR.zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os;\nimport torch;\nimport torch.fft;\nimport torchvision;\nimport numpy as np;\nfrom tqdm import tqdm;\nfrom PIL import Image;\nfrom typing import Tuple;\nfrom random import randint;\nfrom torch import nn, optim;\nfrom torch.utils import data;\nfrom einops import rearrange;\nimport torch.nn.functional as F;\nfrom torch.backends import cudnn;\nfrom torch.utils.data import Dataset;\nfrom torch.nn.init import trunc_normal_;\nfrom torch.nn.parameter import Parameter;\nimport torchvision.transforms.functional as FT;","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T09:15:17.816458Z","iopub.execute_input":"2025-05-29T09:15:17.817148Z","iopub.status.idle":"2025-05-29T09:15:20.440617Z","shell.execute_reply.started":"2025-05-29T09:15:17.817121Z","shell.execute_reply":"2025-05-29T09:15:20.440072Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"cudnn.benchmark = True;\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\");\n\nbatch_size = 64;\nlearning_rate = 1e-3;\nepochs = 8000;","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T09:15:20.441763Z","iopub.execute_input":"2025-05-29T09:15:20.442139Z","iopub.status.idle":"2025-05-29T09:15:20.473912Z","shell.execute_reply.started":"2025-05-29T09:15:20.442112Z","shell.execute_reply":"2025-05-29T09:15:20.473194Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class WindowSelfAttention(nn.Module):\n\n    def __init__(self, dim: int, num_heads: int = 8, window_size: int = 8) -> None:\n        super().__init__();\n        self.num_heads = num_heads;\n        self.window_size = window_size;\n        head_dim = dim // num_heads;\n        self.scale = head_dim ** -0.5;\n        self.query = nn.Conv1d(dim, dim, kernel_size = 1, padding = 0, bias = False);\n        self.key = nn.Conv1d(dim, dim, kernel_size = 1, padding = 0, bias = False);\n        self.value = nn.Conv1d(dim, dim, kernel_size = 1, padding = 0, bias = False);\n        self.beta = nn.Parameter(torch.zeros(num_heads, window_size ** 2, window_size ** 2));\n        self.proj_out = nn.Conv1d(dim, dim, kernel_size = 1, padding = 0, bias = True);\n        trunc_normal_(self.beta, std = 0.02);\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        b, c, h, w = x.shape;\n        # Pad\n        pad_r = (self.window_size - w % self.window_size) % self.window_size;\n        pad_b = (self.window_size - h % self.window_size) % self.window_size;\n        x = F.pad(x, (0, pad_r, 0, pad_b));\n        # Window partition\n        x = rearrange(x, 'b c (h s1) (w s2) -> (b h w) c (s1 s2)', s1 = self.window_size, s2 = self.window_size);\n        # Project\n        q = self.query(x);\n        k = self.key(x);\n        v = self.value(x);\n        # Attention\n        q, k, v = map(lambda t: rearrange(t, 'b (h d) n -> b h d n', h = self.num_heads), [q, k, v]);\n        attn = torch.einsum('b h d n, b h d m -> b h n m', q, k) * self.scale + self.beta;\n        attn = attn.softmax(dim = -1);\n        x = torch.einsum('b h n m, b h d m -> b h d n', attn, v);\n        x = rearrange(x, 'b i c j -> b (i c) j');\n        x = self.proj_out(x);\n        # Reverse window partition\n        x = rearrange(x, 'B c (s1 s2) -> B c s1 s2', s1 = self.window_size, s2 = self.window_size);\n        b = int(x.shape[0] / (h * w / self.window_size / self.window_size));\n        x = rearrange(x, '(b h w) c s1 s2 -> b c (h s1) (w s2)', b = b, h = (h + pad_b) // self.window_size, w = (w + pad_r) // self.window_size);\n        if((pad_r > 0) or (pad_b > 0)):\n            x = x[:, :, :h, :w].contiguous();\n        return x;\n\nclass PCFN(nn.Module):\n\n    def __init__(self, dim: int, growth_rate: float = 2.0, p_rate: float = 0.25) -> None:\n        super().__init__();\n        hidden_dim = int(dim * growth_rate);\n        p_dim = int(hidden_dim * p_rate);\n        self.conv_0 = nn.Conv2d(dim, hidden_dim, kernel_size = 1, padding = 0);\n        self.conv_1 = nn.Conv2d(p_dim, p_dim, kernel_size = 3, padding = 1, padding_mode = \"reflect\");\n        self.act = nn.GELU();\n        self.conv_2 = nn.Conv2d(hidden_dim, dim, kernel_size = 1, padding = 0);\n        self.p_dim = p_dim;\n        self.hidden_dim = hidden_dim;\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        if(self.training):\n            x = self.act(self.conv_0(x));\n            x1, x2 = torch.split(x, [self.p_dim, self.hidden_dim - self.p_dim], dim = 1);\n            x1 = self.act(self.conv_1(x1));\n            x = self.conv_2(torch.cat([x1, x2], dim = 1));\n        else:\n            x = self.act(self.conv_0(x));\n            x[:, :self.p_dim, :, :] = self.act(self.conv_1(x[:, :self.p_dim, :, :]));\n            x = self.conv_2(x);\n        return x;\n\nclass Transformer(nn.Module):\n\n    def __init__(self,\n                 dim: int,\n                 num_heads: int = 4,\n                 window_size: int = 8,\n                 mlp_ratio: int = 4) -> None:\n        super().__init__();\n        self.attn = WindowSelfAttention(dim, num_heads, window_size);\n        self.pcfn = PCFN(dim, mlp_ratio);\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.attn(F.normalize(x)) + x;\n        x = self.pcfn(F.normalize(x)) + x;\n        return x;\n\nclass SRViT(nn.Module):\n\n    def __init__(self, n_feats: int = 40, n_heads: int = 8, ratio: int = 2, blocks = 5, upscaling_factor: int = 4) -> None:\n        super(SRViT, self).__init__();\n        self.head = nn.Conv2d(3, n_feats, 3, 1, 1);\n        self.body = nn.Sequential(*[Transformer(n_feats, n_heads, 8, ratio) for i in range(blocks)]);\n        self.upsampling = nn.Sequential(\n            nn.Conv2d(n_feats, 3 * upscaling_factor ** 2, kernel_size = 3, padding = 1, padding_mode = \"reflect\"),\n            nn.PixelShuffle(upscaling_factor)\n        );\n        \n    def forward(self, x):\n        res = F.interpolate(x, size = (x.size(2) * 4, x.size(3) * 4));\n        x = self.head(x);\n        x = self.upsampling(self.body(x) + x);\n        return x + res;","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T09:15:20.474739Z","iopub.execute_input":"2025-05-29T09:15:20.475047Z","iopub.status.idle":"2025-05-29T09:15:20.615747Z","shell.execute_reply.started":"2025-05-29T09:15:20.475022Z","shell.execute_reply":"2025-05-29T09:15:20.614947Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def transform(input: torch.Tensor, target: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    if(randint(0, 10) > 5):\n        input = FT.vflip(input);\n        target = FT.vflip(target);\n    if(randint(0, 10) > 5):\n        input = FT.hflip(input);\n        target = FT.hflip(target);\n    angle = randint(-30, 30);\n    input = FT.rotate(input, angle, interpolation = torchvision.transforms.InterpolationMode.BILINEAR);\n    target = FT.rotate(target, angle, interpolation = torchvision.transforms.InterpolationMode.BILINEAR);\n    return (input, target);\n\nclass SWIRDataset(Dataset):\n\n    def __init__(self, root_dir: str, transform) -> None:\n        self.root_dir = root_dir;\n        self.transform = transform;\n        self.img_64 = [];\n        self.img_256 = [];\n        for idx in range(715):\n            self.img_64.append(torch.cat([FT.to_tensor(Image.open(os.path.join(self.root_dir, \"64\", \"800\", f\"{(idx + 1):04}.jpg\")).convert('L')),\n                                          FT.to_tensor(Image.open(os.path.join(self.root_dir, \"64\", \"1050\", f\"{(idx + 1):04}.jpg\")).convert('L')),\n                                          FT.to_tensor(Image.open(os.path.join(self.root_dir, \"64\", \"1550\", f\"{(idx + 1):04}.jpg\")).convert('L'))], dim = 0));\n            self.img_256.append(torch.cat([FT.to_tensor(Image.open(os.path.join(self.root_dir, \"256\", \"800\", f\"{(idx + 1):04}.jpg\")).convert('L')),\n                                           FT.to_tensor(Image.open(os.path.join(self.root_dir, \"256\", \"1050\", f\"{(idx + 1):04}.jpg\")).convert('L')),\n                                           FT.to_tensor(Image.open(os.path.join(self.root_dir, \"256\", \"1550\", f\"{(idx + 1):04}.jpg\")).convert('L'))], dim = 0));\n    \n    def __len__(self) -> int:\n        return 715;\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        img_64, img_256 = self.transform(self.img_64[idx], self.img_256[idx]);\n        return img_64, img_256;","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T09:15:20.616483Z","iopub.execute_input":"2025-05-29T09:15:20.616741Z","iopub.status.idle":"2025-05-29T09:15:20.635872Z","shell.execute_reply.started":"2025-05-29T09:15:20.616715Z","shell.execute_reply":"2025-05-29T09:15:20.635248Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class FFTLoss(nn.Module):\n\n    def __init__(self, loss_weight: float = 1.0, reduction: str = 'mean') -> None:\n        super().__init__();\n        self.loss_weight = loss_weight;\n        self.criterion = torch.nn.L1Loss(reduction = reduction);\n\n    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n        pred_fft = torch.fft.rfft2(pred);\n        target_fft = torch.fft.rfft2(target);\n        pred_fft = torch.stack([pred_fft.real, pred_fft.imag], dim = -1);\n        target_fft = torch.stack([target_fft.real, target_fft.imag], dim = -1);\n        return self.loss_weight * (self.criterion(pred_fft, target_fft));","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T09:15:20.637450Z","iopub.execute_input":"2025-05-29T09:15:20.637717Z","iopub.status.idle":"2025-05-29T09:15:20.654686Z","shell.execute_reply.started":"2025-05-29T09:15:20.637700Z","shell.execute_reply":"2025-05-29T09:15:20.654102Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def main():\n    dataset = SWIRDataset('SWIR', transform);\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True);\n    net = SRViT().train().to(device);\n    opt_net = optim.Adam(net.parameters(), lr = learning_rate);\n    fft = FFTLoss(0.1);\n    avg_pix_loss = 0.0;\n    avg_fft_loss = 0.0;\n    it = 0;\n    for i in tqdm(range(epochs)):\n        for lr, hr in iter(dataloader):\n            lr = lr.to(device);\n            hr = hr.to(device);\n\n            sr = net(lr);\n            \n            pix_loss = F.l1_loss(sr, hr);\n            fft_loss = fft(sr, hr);\n            avg_pix_loss += pix_loss.item();\n            avg_fft_loss += fft_loss.item();\n            total_loss = pix_loss + fft_loss;\n            opt_net.zero_grad();\n            total_loss.backward();\n            opt_net.step();\n            it += 1;\n        if(((i + 1) % 100) == 0):\n            print(\"epoch: {:d}, pix: {:f}, fft: {:f}\".format(i + 1, avg_pix_loss / it, avg_fft_loss / it));\n            torch.save(net.state_dict(), 'srvit_{:d}.pth'.format(i + 1));\n            avg_pix_loss = 0.0;\n            avg_fft_loss = 0.0;\n            it = 0;\n        if(((i + 1) % 1500) == 0):\n            for param_group in opt_net.param_groups:\n                param_group['lr'] /= 2.0;\n\nmain();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T09:15:20.655355Z","iopub.execute_input":"2025-05-29T09:15:20.655535Z","iopub.status.idle":"2025-05-29T17:35:54.595545Z","shell.execute_reply.started":"2025-05-29T09:15:20.655521Z","shell.execute_reply":"2025-05-29T17:35:54.594839Z"}},"outputs":[{"name":"stderr","text":"  1%|▏         | 100/8000 [06:17<8:15:50,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 100, pix: 0.091184, fft: 0.696591\n","output_type":"stream"},{"name":"stderr","text":"  2%|▎         | 200/8000 [12:32<8:07:54,  3.75s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 200, pix: 0.075961, fft: 0.646417\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 300/8000 [18:48<8:02:36,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 300, pix: 0.071911, fft: 0.632141\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 400/8000 [25:03<7:57:52,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 400, pix: 0.070325, fft: 0.628124\n","output_type":"stream"},{"name":"stderr","text":"  6%|▋         | 500/8000 [31:18<7:51:04,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 500, pix: 0.068901, fft: 0.624101\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 600/8000 [37:34<7:43:44,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 600, pix: 0.068174, fft: 0.620369\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 700/8000 [43:49<7:36:36,  3.75s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 700, pix: 0.067260, fft: 0.616512\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 800/8000 [50:04<7:30:42,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 800, pix: 0.066831, fft: 0.614156\n","output_type":"stream"},{"name":"stderr","text":" 11%|█▏        | 900/8000 [56:19<7:24:10,  3.75s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 900, pix: 0.066153, fft: 0.611085\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▎        | 1000/8000 [1:02:34<7:18:44,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1000, pix: 0.065857, fft: 0.611202\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 1100/8000 [1:08:49<7:13:53,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1100, pix: 0.065449, fft: 0.609500\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 1200/8000 [1:15:05<7:06:10,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1200, pix: 0.065068, fft: 0.609297\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▋        | 1300/8000 [1:21:20<6:59:37,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1300, pix: 0.064792, fft: 0.607571\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 1400/8000 [1:27:35<6:53:57,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1400, pix: 0.064226, fft: 0.605794\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 1500/8000 [1:33:50<6:47:11,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1500, pix: 0.064057, fft: 0.606664\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 1600/8000 [1:40:06<6:41:49,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1600, pix: 0.062994, fft: 0.604130\n","output_type":"stream"},{"name":"stderr","text":" 21%|██▏       | 1700/8000 [1:46:21<6:35:55,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1700, pix: 0.062948, fft: 0.603903\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▎       | 1800/8000 [1:52:36<6:28:13,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1800, pix: 0.062520, fft: 0.602401\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 1900/8000 [1:58:52<6:23:11,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 1900, pix: 0.062549, fft: 0.602243\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 2000/8000 [2:05:08<6:17:12,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2000, pix: 0.062156, fft: 0.601105\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▋       | 2100/8000 [2:11:24<6:09:49,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2100, pix: 0.062042, fft: 0.599773\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 2200/8000 [2:17:39<6:04:08,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2200, pix: 0.061789, fft: 0.599316\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 2300/8000 [2:23:55<5:58:38,  3.78s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2300, pix: 0.061664, fft: 0.599296\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 2400/8000 [2:30:11<5:51:26,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2400, pix: 0.061613, fft: 0.599888\n","output_type":"stream"},{"name":"stderr","text":" 31%|███▏      | 2500/8000 [2:36:27<5:45:24,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2500, pix: 0.061496, fft: 0.599121\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▎      | 2600/8000 [2:42:43<5:38:25,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2600, pix: 0.061283, fft: 0.598686\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 2700/8000 [2:48:58<5:32:34,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2700, pix: 0.061229, fft: 0.598160\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 2800/8000 [2:55:14<5:26:42,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2800, pix: 0.060836, fft: 0.597658\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▋      | 2900/8000 [3:01:30<5:20:26,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 2900, pix: 0.060853, fft: 0.598230\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 3000/8000 [3:07:45<5:15:44,  3.79s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3000, pix: 0.060639, fft: 0.597088\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 3100/8000 [3:14:01<5:07:03,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3100, pix: 0.059892, fft: 0.596114\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 3200/8000 [3:20:17<5:01:12,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3200, pix: 0.059795, fft: 0.595485\n","output_type":"stream"},{"name":"stderr","text":" 41%|████▏     | 3300/8000 [3:26:33<4:55:12,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3300, pix: 0.059571, fft: 0.594390\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▎     | 3400/8000 [3:32:48<4:48:45,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3400, pix: 0.059582, fft: 0.595654\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 3500/8000 [3:39:04<4:42:53,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3500, pix: 0.059470, fft: 0.595834\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 3600/8000 [3:45:19<4:37:22,  3.78s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3600, pix: 0.059392, fft: 0.595383\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▋     | 3700/8000 [3:51:35<4:29:39,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3700, pix: 0.059361, fft: 0.595302\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 3800/8000 [3:57:50<4:22:56,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3800, pix: 0.059108, fft: 0.593937\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 3900/8000 [4:04:05<4:17:00,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 3900, pix: 0.059167, fft: 0.595123\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 4000/8000 [4:10:20<4:10:51,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4000, pix: 0.058936, fft: 0.593702\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████▏    | 4100/8000 [4:16:35<4:04:35,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4100, pix: 0.058916, fft: 0.594553\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▎    | 4200/8000 [4:22:50<3:58:48,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4200, pix: 0.058883, fft: 0.594549\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 4300/8000 [4:29:05<3:52:00,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4300, pix: 0.058825, fft: 0.594475\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 4400/8000 [4:35:21<3:45:24,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4400, pix: 0.058813, fft: 0.594435\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▋    | 4500/8000 [4:41:36<3:39:15,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4500, pix: 0.058626, fft: 0.593842\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▊    | 4600/8000 [4:47:51<3:33:16,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4600, pix: 0.057936, fft: 0.591740\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 4700/8000 [4:54:06<3:27:22,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4700, pix: 0.057996, fft: 0.593537\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 4800/8000 [5:00:21<3:20:47,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4800, pix: 0.057918, fft: 0.592452\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████▏   | 4900/8000 [5:06:36<3:14:15,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 4900, pix: 0.057772, fft: 0.592333\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▎   | 5000/8000 [5:12:51<3:07:49,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5000, pix: 0.057925, fft: 0.592763\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 5100/8000 [5:19:06<3:01:47,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5100, pix: 0.057673, fft: 0.591272\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 5200/8000 [5:25:22<2:55:29,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5200, pix: 0.057801, fft: 0.592767\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▋   | 5300/8000 [5:31:37<2:49:24,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5300, pix: 0.057728, fft: 0.593437\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 5400/8000 [5:37:52<2:43:02,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5400, pix: 0.057642, fft: 0.592921\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 5500/8000 [5:44:07<2:36:29,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5500, pix: 0.057543, fft: 0.591707\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 5600/8000 [5:50:22<2:30:42,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5600, pix: 0.057601, fft: 0.592371\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████▏  | 5700/8000 [5:56:37<2:24:10,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5700, pix: 0.057369, fft: 0.590957\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▎  | 5800/8000 [6:02:52<2:18:01,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5800, pix: 0.057588, fft: 0.592881\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 5900/8000 [6:09:07<2:11:43,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 5900, pix: 0.057421, fft: 0.592181\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 6000/8000 [6:15:22<2:05:12,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6000, pix: 0.057390, fft: 0.591710\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▋  | 6100/8000 [6:21:37<1:58:52,  3.75s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6100, pix: 0.057131, fft: 0.592216\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 6200/8000 [6:27:52<1:53:00,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6200, pix: 0.057094, fft: 0.591173\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 6300/8000 [6:34:08<1:46:53,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6300, pix: 0.056954, fft: 0.590567\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 6400/8000 [6:40:24<1:40:25,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6400, pix: 0.056990, fft: 0.591739\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████▏ | 6500/8000 [6:46:40<1:34:11,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6500, pix: 0.056874, fft: 0.590762\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▎ | 6600/8000 [6:52:55<1:27:44,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6600, pix: 0.056972, fft: 0.590914\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 6700/8000 [6:59:10<1:21:26,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6700, pix: 0.056881, fft: 0.590867\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 6800/8000 [7:05:25<1:15:11,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6800, pix: 0.056839, fft: 0.590773\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▋ | 6900/8000 [7:11:40<1:08:53,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 6900, pix: 0.056596, fft: 0.588996\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 7000/8000 [7:17:56<1:02:44,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 7000, pix: 0.056812, fft: 0.590671\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 7100/8000 [7:24:11<56:28,  3.77s/it]  ","output_type":"stream"},{"name":"stdout","text":"epoch: 7100, pix: 0.056691, fft: 0.589806\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 7200/8000 [7:30:27<50:09,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 7200, pix: 0.056776, fft: 0.590907\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████▏| 7300/8000 [7:36:43<43:57,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 7300, pix: 0.056890, fft: 0.592414\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▎| 7400/8000 [7:42:58<37:41,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 7400, pix: 0.056817, fft: 0.592108\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 7500/8000 [7:49:14<31:21,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 7500, pix: 0.056622, fft: 0.590086\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 7600/8000 [7:55:29<25:06,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 7600, pix: 0.056567, fft: 0.591078\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▋| 7700/8000 [8:01:45<18:50,  3.77s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 7700, pix: 0.056585, fft: 0.591242\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 7800/8000 [8:08:01<12:32,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 7800, pix: 0.056473, fft: 0.590530\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▉| 7900/8000 [8:14:16<06:16,  3.76s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 7900, pix: 0.056485, fft: 0.590250\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 8000/8000 [8:20:31<00:00,  3.75s/it]","output_type":"stream"},{"name":"stdout","text":"epoch: 8000, pix: 0.056320, fft: 0.588702\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6}]}