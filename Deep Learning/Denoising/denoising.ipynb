{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://drive.google.com/file/d/1qumjvCdnDQvZdrS_o-MMgRatNLFd9QTd/view?usp=sharing\n!conda install -y gdown\n!gdown --id \"1qumjvCdnDQvZdrS_o-MMgRatNLFd9QTd\"\n!unzip -q Minerals.zip\n!rm Minerals.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T15:23:48.737881Z","iopub.execute_input":"2025-04-23T15:23:48.738951Z","iopub.status.idle":"2025-04-23T15:24:05.922801Z","shell.execute_reply.started":"2025-04-23T15:23:48.738912Z","shell.execute_reply":"2025-04-23T15:24:05.922010Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: conda: command not found\n/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1qumjvCdnDQvZdrS_o-MMgRatNLFd9QTd\nTo: /kaggle/working/Minerals.zip\n100%|██████████████████████████████████████| 13.8M/13.8M [00:00<00:00, 70.4MB/s]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os;\nimport torch;\nimport torch.fft;\nimport torchvision;\nimport numpy as np;\nfrom PIL import Image;\nfrom typing import Tuple;\nfrom random import randint;\nfrom torch import nn, optim;\nfrom torch.utils import data;\nimport torch.nn.functional as F;\nfrom torch.backends import cudnn;\nfrom torch.utils.data import Dataset;\nfrom torch.nn.parameter import Parameter;\nimport torchvision.transforms.functional as FT;","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T15:48:26.837364Z","iopub.execute_input":"2025-04-23T15:48:26.837641Z","iopub.status.idle":"2025-04-23T15:48:26.842437Z","shell.execute_reply.started":"2025-04-23T15:48:26.837624Z","shell.execute_reply":"2025-04-23T15:48:26.841671Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"cudnn.benchmark = True;\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\");\n\nbatch_size = 16;\nlearning_rate = 3e-4;\nepochs = 2500;","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T15:48:26.843486Z","iopub.execute_input":"2025-04-23T15:48:26.843698Z","iopub.status.idle":"2025-04-23T15:48:26.862636Z","shell.execute_reply.started":"2025-04-23T15:48:26.843682Z","shell.execute_reply":"2025-04-23T15:48:26.862093Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class UNet(nn.Module):\n\n    def __init__(self) -> None:\n        super().__init__();\n        self.enc0 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size = 5, padding = 2, stride = 2),\n            nn.PReLU(64)\n        );\n        self.enc1 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size = 5, padding = 2, stride = 2),\n            nn.PReLU(128)\n        );\n        self.enc2 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size = 5, padding = 2, stride = 2),\n            nn.PReLU(256)\n        );\n        self.enc3 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size = 5, padding = 2, stride = 2),\n            nn.PReLU(512)\n        );\n        self.dec3 = nn.Sequential(\n            nn.ConvTranspose2d(512, 256, kernel_size = 5, padding = 2, output_padding = 1, stride = 2),\n            nn.PReLU(256)\n        );\n        self.dec2 = nn.Sequential(\n            nn.ConvTranspose2d(512, 128, kernel_size = 5, padding = 2, output_padding = 1, stride = 2),\n            nn.PReLU(128)\n        );\n        self.dec1 = nn.Sequential(\n            nn.ConvTranspose2d(256, 64, kernel_size = 5, padding = 2, output_padding = 1, stride = 2),\n            nn.PReLU(64)\n        );\n        self.dec0 = nn.Sequential(\n            nn.ConvTranspose2d(128, 3, kernel_size = 5, padding = 2, output_padding = 1, stride = 2)\n        );\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x0 = self.enc0(x);\n        x1 = self.enc1(x0);\n        x2 = self.enc2(x1);\n        x3 = self.enc3(x2);\n        y = self.dec3(x3);\n        y = self.dec2(torch.cat([F.interpolate(y, size = x2.shape[2:], mode = \"nearest\"), x2], dim = 1));\n        y = self.dec1(torch.cat([F.interpolate(y, size = x1.shape[2:], mode = \"nearest\"), x1], dim = 1));\n        y = self.dec0(torch.cat([F.interpolate(y, size = x0.shape[2:], mode = \"nearest\"), x0], dim = 1));\n        return y;","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T15:48:26.863697Z","iopub.execute_input":"2025-04-23T15:48:26.863904Z","iopub.status.idle":"2025-04-23T15:48:26.875900Z","shell.execute_reply.started":"2025-04-23T15:48:26.863884Z","shell.execute_reply":"2025-04-23T15:48:26.875146Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def transform(input: torch.Tensor, target: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    target = F.interpolate(target.unsqueeze(0), size = (64, 64), mode = \"bicubic\").squeeze(0);\n    if(randint(0, 10) > 5):\n        input = FT.vflip(input);\n        target = FT.vflip(target);\n    if(randint(0, 10) > 5):\n        input = FT.hflip(input);\n        target = FT.hflip(target);\n    angle = randint(-30, 30);\n    input = FT.rotate(input, angle, interpolation = torchvision.transforms.InterpolationMode.BILINEAR);\n    target = FT.rotate(target, angle, interpolation = torchvision.transforms.InterpolationMode.BILINEAR);\n    return (input, target);\n\nclass MineralDataset(Dataset):\n\n    def __init__(self, root_dir: str, transform) -> None:\n        self.root_dir = root_dir;\n        self.transform = transform;\n\n    def __len__(self) -> int:\n        return 334;\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        img_64 = torch.cat([FT.to_tensor(Image.open(os.path.join(self.root_dir, \"64\", \"800\", f\"{(idx + 1):03}_800.jpg\")).convert('L')),\n                            FT.to_tensor(Image.open(os.path.join(self.root_dir, \"64\", \"1050\", f\"{(idx + 1):03}_1050.jpg\")).convert('L')),\n                            FT.to_tensor(Image.open(os.path.join(self.root_dir, \"64\", \"1550\", f\"{(idx + 1):03}_1550.jpg\")).convert('L'))], dim = 0);\n        img_256 = torch.cat([FT.to_tensor(Image.open(os.path.join(self.root_dir, \"256\", \"800\", f\"{(idx + 1):03}_800.jpg\")).convert('L')),\n                             FT.to_tensor(Image.open(os.path.join(self.root_dir, \"256\", \"1050\", f\"{(idx + 1):03}_1050.jpg\")).convert('L')),\n                             FT.to_tensor(Image.open(os.path.join(self.root_dir, \"256\", \"1550\", f\"{(idx + 1):03}_1550.jpg\")).convert('L'))], dim = 0);\n        img_64, img_256 = self.transform(img_64, img_256);\n        return img_64, img_256;","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T15:48:26.877053Z","iopub.execute_input":"2025-04-23T15:48:26.877280Z","iopub.status.idle":"2025-04-23T15:48:26.896074Z","shell.execute_reply.started":"2025-04-23T15:48:26.877258Z","shell.execute_reply":"2025-04-23T15:48:26.895485Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class FFTLoss(nn.Module):\n\n    def __init__(self, loss_weight: float = 1.0, reduction: str = 'mean') -> None:\n        super().__init__();\n        self.loss_weight = loss_weight;\n        self.criterion = torch.nn.L1Loss(reduction = reduction);\n\n    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n        pred_fft = torch.fft.rfft2(pred);\n        target_fft = torch.fft.rfft2(target);\n        pred_fft = torch.stack([pred_fft.real, pred_fft.imag], dim = -1);\n        target_fft = torch.stack([target_fft.real, target_fft.imag], dim = -1);\n        return self.loss_weight * (self.criterion(pred_fft, target_fft));","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T15:48:26.896672Z","iopub.execute_input":"2025-04-23T15:48:26.896872Z","iopub.status.idle":"2025-04-23T15:48:26.914013Z","shell.execute_reply.started":"2025-04-23T15:48:26.896858Z","shell.execute_reply":"2025-04-23T15:48:26.913412Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def main():\n    dataset = MineralDataset('Minerals', transform);\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = True);\n    net = UNet().train().to(device);\n    opt_net = optim.Adam(net.parameters(), lr = learning_rate);\n    fft = FFTLoss(0.1);\n    avg_pix_loss = 0.0;\n    avg_fft_loss = 0.0;\n    it = 0;\n    for i in range(epochs):\n        for lr, hr in iter(dataloader):\n            lr = lr.to(device);\n            hr = hr.to(device);\n\n            sr = net(lr);\n            \n            pix_loss = F.l1_loss(sr, hr);\n            fft_loss = fft(sr, hr);\n            avg_pix_loss += pix_loss.item();\n            avg_fft_loss += fft_loss.item();\n            total_loss = pix_loss + fft_loss;\n            opt_net.zero_grad();\n            total_loss.backward();\n            opt_net.step();\n            it += 1;\n        if(((i + 1) % 100) == 0):\n            print(\"epoch: {:d}, pix: {:f}, fft: {:f}\".format(i + 1, avg_pix_loss / it, avg_fft_loss / it));\n            torch.save(net.state_dict(), 'unet_{:d}.pth'.format(i + 1));\n            avg_pix_loss = 0.0;\n            avg_fft_loss = 0.0;\n            it = 0;\n        if(((i + 1) % 500) == 0):\n            for param_group in opt_net.param_groups:\n                param_group['lr'] /= 2.0;\n\nmain();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T15:48:26.915204Z","iopub.execute_input":"2025-04-23T15:48:26.915452Z","iopub.status.idle":"2025-04-23T16:43:17.161536Z","shell.execute_reply.started":"2025-04-23T15:48:26.915436Z","shell.execute_reply":"2025-04-23T16:43:17.160689Z"}},"outputs":[{"name":"stdout","text":"epoch: 100, pix: 0.052502, fft: 0.171430\nepoch: 200, pix: 0.045331, fft: 0.151658\nepoch: 300, pix: 0.040792, fft: 0.145294\nepoch: 400, pix: 0.037367, fft: 0.139061\nepoch: 500, pix: 0.035157, fft: 0.134398\nepoch: 600, pix: 0.033020, fft: 0.129531\nepoch: 700, pix: 0.031991, fft: 0.127005\nepoch: 800, pix: 0.031300, fft: 0.125308\nepoch: 900, pix: 0.030759, fft: 0.123918\nepoch: 1000, pix: 0.030327, fft: 0.122847\nepoch: 1100, pix: 0.029580, fft: 0.120815\nepoch: 1200, pix: 0.029228, fft: 0.119850\nepoch: 1300, pix: 0.028988, fft: 0.119118\nepoch: 1400, pix: 0.028807, fft: 0.118663\nepoch: 1500, pix: 0.028618, fft: 0.118114\nepoch: 1600, pix: 0.028304, fft: 0.117167\nepoch: 1700, pix: 0.028179, fft: 0.116804\nepoch: 1800, pix: 0.028060, fft: 0.116451\nepoch: 1900, pix: 0.027987, fft: 0.116247\nepoch: 2000, pix: 0.027908, fft: 0.116025\nepoch: 2100, pix: 0.027744, fft: 0.115496\nepoch: 2200, pix: 0.027708, fft: 0.115389\nepoch: 2300, pix: 0.027631, fft: 0.115137\nepoch: 2400, pix: 0.027608, fft: 0.115051\nepoch: 2500, pix: 0.027571, fft: 0.114942\n","output_type":"stream"}],"execution_count":16}]}